---
title: "Tutorial"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

## Introduction

This is a tutorial accompanying the paper [Batch effects in population genomic studies with low-coverage whole genome sequencing data: causes, detection, and mitigation](https://doi.org/10.22541/au.162791857.78788821/v2) by R. Nicolas Lou and Nina Overgaard Therkildsen. In this tutorial, we provide a small subset of the data used in our paper and offer hands-on exercises on the detection and mitigation of batch effects in low-coverage whole genome sequencing (lcWGS) data. 

We will focus on four main causes of batch effects in this tutorial:

1. Difference in sequencing chemistry (two vs. four channel) leading to the presence / absence of poly-G tails

2. Separate sequencing runs leading to different levels of miscalibration in base quality scores

3. Difference in read type and read length leading to different levels of reference bias / alignment error

4. Difference in levels of DNA degradation

After taking this tutorial, you will learn about the different causes of batch effects, and will be able to perform some simple bioinformatic methods to detect and mitigate their impacts. 

This tutorial is under active development and will be finalized before the publication of our paper.

## Some preparation

To start, first clone this GitHub repo to your Linux server (e.g. `git clone https://github.com/therkildsen-lab/batch-effect.git`). Even though the size of our individual files are not very large, this may still take some time.

Change your working directory to the tutorial folder within this GitHub repo (e.g. `cd /workdir/batch-effect/tutorial`) and inspect the content of this folder (e.g. `ls`). As you can see, there is a single folder called `data` that stores all the data needed for this tutorial. 

Then, define the following variables on your Linux server. Make sure that you **modify these paths** to reflect the locations on your file system. 

```{bash eval=FALSE}
## Location of the tutorial folder in the batch-effect Github repo
BASEDIR=/workdir/batch-effect/tutorial
## Path to the reference to the gadMor3 reference genome
REFERENCE=/workdir/cod/reference_seqs/gadMor3.fasta
## Path to fastp (https://github.com/OpenGene/fastp)
FASTP=/workdir/programs/fastp_0.19.7/fastp
## Path to fastqc (https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
FASTQC=fastqc
## Path to AGNSD (https://github.com/ANGSD/angsd)
ANGSD=/programs/angsd0.930/angsd/angsd 
## Path to the realSFS module in AGNSD
REALSFS=/workdir/programs/angsd0.931/angsd/misc/realSFS
```

You will need to create a `results` folder within `tutorial` to store your output files. To do so, run 

```{bash eval=FALSE}
makdir $BASEDIR/results
```

Also, you will need to use R in this tutorial for data wrangling and visualization. We recommend you to use RStudio server, but you can also launch a another session on your Linux server and use R there. Install the following packages with `install.packages()` if you don't have them installed already, and load them using `library()` as shown below. 

```{r eval=TRUE}
library(tidyverse)
library(cowplot)
library(ggstatsplot)
library(statsExpressions)
```

## Poly-G tail 

Across Illumina platforms, an important change is the shift from a four-channel system (used e.g., on HiSeq instruments) where each DNA base is detected with a different fluorescent dye, to a two-channel chemistry, that uses the combinations of two different dyes. With the two-channel system (implemented on newer platforms like NextSeq and NovaSeq), G is called when there is little to no fluorescence signal. Accordingly, the absence of a signal can result from a true G base in the DNA template, but any low-intensity fluorescence signal (regardless of the true base) may also lead to a G call, which becomes problematic.

Here, we will inspect a pair of fastq files (`before_trimming_f.fastq.gz` and `before_trimming_r.fastq.gz`) generated by a NextSeq sequencer. Specifically, we will perform two different trimming operations, and will compare the base composition per position in the raw and trimmed fastq files. 

#### Poly-G tail trimming with fastp

Poly-G tail trimming looks for long stretches of G base at the end of sequencing reads and removes them from the fastq file. 

```{bash eval=FALSE}
$FASTP --trim_poly_g -L -A \
  -i $BASEDIR/data/before_trimming_f.fastq.gz \
  -I $BASEDIR/data/before_trimming_r.fastq.gz \
  -o $BASEDIR/results/poly_g_trimming_f.fastq.gz \
  -O $BASEDIR/results/poly_g_trimming_r.fastq.gz \
  -h $BASEDIR/results/poly_g_trimming.html \
  -j $BASEDIR/results/poly_g_trimming.json
```

#### Sliding window trimming with fastp

Sliding window trimming moves a window from the beginning to the end of a read. Once the average base quality score falls below a certain threshold, everything after the window will be removed. 

```{bash eval=FALSE}
$FASTP --trim_poly_g -L -A --cut_right \
  -i $BASEDIR/data/before_trimming_f.fastq.gz \
  -I $BASEDIR/data/before_trimming_r.fastq.gz \
  -o $BASEDIR/results/sliding_window_trimming_f.fastq.gz \
  -O $BASEDIR/results/sliding_window_trimming_r.fastq.gz \
  -h $BASEDIR/results/sliding_window_trimming.html \
  -j $BASEDIR/results/sliding_window_trimming.json
```

#### Run FastQC

We use fastQC to compute the average base composition of each position along the sequencing reads. 

```{bash eval=FALSE}
$FASTQC $BASEDIR/data/before_trimming_f.fastq.gz -o $BASEDIR/results/
$FASTQC $BASEDIR/results/poly_g_trimming_f.fastq.gz -o $BASEDIR/results/
$FASTQC $BASEDIR/results/sliding_window_trimming_f.fastq.gz -o $BASEDIR/results/
```

#### Visualize base composition

Run the following with R to compile and plot the base composition generation by FastQC. 

```{r eval=TRUE, fig.height=6, fig.width=4}
basedir="/workdir/batch-effect/tutorial/results/"
file_list=c("before_trimming_f_fastqc", "poly_g_trimming_f_fastqc", "sliding_window_trimming_f_fastqc")
type_list <- c("no trimming", "poly-G trimming", "sliding-window trimming")
for (i in 1:3){
  file <- file_list[i]
  type <- type_list[i]
  unzip(str_c(basedir, file, ".zip"), exdir = basedir)
  fastqc_data <- read_lines(file = str_c(basedir, file, "/fastqc_data.txt"))
  first_line <- which(str_detect(fastqc_data, ">>Per base sequence content")) + 1
  last_line <- which(str_detect(fastqc_data, ">>Per sequence GC content")) - 2
  per_base_seq_content_polyg_trimmed <- fastqc_data[first_line:last_line] %>%
    read_tsv() %>%
    rename(position=`#Base`) %>%
    pivot_longer(2:5, names_to = "base", values_to = "percentage") %>%
    mutate(type = type)
  if (i == 1) {
    per_base_seq_content_polyg_trimmed_final <- per_base_seq_content_polyg_trimmed
  } else {
    per_base_seq_content_polyg_trimmed_final <- bind_rows(per_base_seq_content_polyg_trimmed_final, per_base_seq_content_polyg_trimmed)
  }
}

seq_content_p <- per_base_seq_content_polyg_trimmed_final %>%
  mutate(position = as_factor(position)) %>%
  ggplot(aes(x=position, y=percentage, color=base, group=base)) +
  geom_line(size=0.8) +
  scale_color_manual(values = c("#749dae", "#5445b1", "orange", "#cd3341")) +
  xlab("read position (in bp)") +
  facet_wrap(~type, nrow = 3) +
  cowplot::theme_cowplot() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
seq_content_p
```

The raw fastq file has a strong enrichment of G bases toward the end of sequencing reads. 

## Base quality score miscalibration

In an ideal scenario, a base quality score should accurately reflect the probability of the base call being correct. In practice, however, these scores are often incorrectly calibrated (Callahan et al., 2016; Ni & Stoneking, 2016), which can lead to batch effects if the levels of such biases differ across sequencing runs. 

Here, we will compare the heterozygosity estimation using a relaxed vs. stringent base quality filter to detect base quality score miscalibration in samples from the same Atlanlatic cod population that are split into two sequencing batches. 

#### Heterozygosity estimation

We use ANGSD to estimate the heterozygosity of individual bam files in `bam_list_bq.txt` using two different minimum base quality filters (20 vs. 33).

```{bash eval=FALSE}
MINDP=2
MAXDP=10
MINMAPQ=30

for MINQ in {20,33}; do
  for LINE in `cat $BASEDIR/data/bam_list_bq.txt`; do
      NAME_TEMP=`echo "${LINE%.*}"`
      NAME=`echo "${NAME_TEMP##*/}"`
  	  echo $NAME
      OUTBASE=$NAME'_mindp'$MINDP'_maxdp'$MAXDP'_minq'$MINQ'_minmapq'$MINMAPQ
      
      ## Get saf file
      $ANGSD \
      -i $LINE \
      -anc $REFERENCE \
      -out $BASEDIR/results/$OUTBASE \
      -doSaf 1 \
      -GL 1 \
      -P 8 \
      -doCounts 1 \
      -setMinDepth $MINDP \
      -setMaxDepth $MAXDP \
      -minQ $MINQ \
      -minmapq $MINMAPQ 

      ## Estimate sfs
      /workdir/programs/angsd0.931/angsd/misc/realSFS \
      $BASEDIR/results/$OUTBASE'.saf.idx' \
      -tole 0.0000001 \
      -P 8 \
      -seed 42 \
      > $BASEDIR/results/$OUTBASE'.ml'
  done
done
```

## Visulization 

We perform visualization and statistical analysis using R. 

```{r eval=TRUE, fig.width=12, fig.height=5}
basedir="/workdir/batch-effect/tutorial/"
sample_table <- read_tsv(str_c(basedir, "data/sample_table_bq.tsv"))
for (i in seq_len(nrow(sample_table))){
  data_type <- sample_table$data_type[i]
  if (data_type=="se"){
    prefix <- str_c(sample_table$sample_seq_id[i], "_bt2_gadMor3_sorted_dedup_realigned_subsetted_bq_mindp2_maxdp10_minq")
  } else {
    prefix <- str_c(sample_table$sample_seq_id[i], "_bt2_gadMor3_sorted_dedup_overlapclipped_realigned_subsetted_bq_mindp2_maxdp10_minq")
  }
  for (minq in c(20, 33)) {
    ml <- read_delim(str_c(basedir, "results/", prefix, minq, "_minmapq30.ml"), col_names = FALSE, delim = " ")
    het <- ml$X2/(ml$X1 + ml$X2 + ml$X3)
    line <- tibble(het=het, sample_id=sample_table$sample_id_corrected[i], data_type=sample_table$data_type[i], minq=minq)
    if (i==1 & minq==20) {
      het_final <- line
    } else{
      het_final <- bind_rows(het_final, line)
    }
  }
}

het_final %>%
  mutate(data_type=ifelse(data_type=="pe", "NextSeq-150PE (more miscalibration in base quality scores)", "HiSeq-125SE (less miscalibration in base quality scores)")) %>%
  mutate(filter=ifelse(minq==20, "relaxed base quality filter (minQ = 20)", "stringent base quality filter (minQ = 33)")) %>%
  mutate(data_type=factor(data_type, levels = c("NextSeq-150PE (more miscalibration in base quality scores)", "HiSeq-125SE (less miscalibration in base quality scores)"))) %>%
  ggstatsplot::grouped_ggwithinstats(
  x = filter,
  y = het,
  #type = "np", # non-parametric statistics
  point.path.args=list(alpha=0.2),
  xlab = element_blank(),
  ylab = "estimated heterozygosity",
  grouping.var = data_type,
  ggtheme = theme_ggstatsplot(),
  bf.message = FALSE,
  ggplot.component = list(theme(panel.grid = element_blank(),
                                axis.line = element_line()))
  )
```

Note that since we took a very small subsample of the data, the statiscal signficance is not exactly the same as what our paper shows. Here, the NextSeq-150PE samples get signficantly lower heterozygosity estimates after the filter is applied, but the HiSeq-125PE samples are not significantly affected by the filter although there is a trend of increased heterozygosity estimates after the filter is applied.

This suggests that base qualities are likely to be overestimated in the NextSeq-150PE batch, and underestimated in the HiSeq-125PE batch. This could cause an inflation of hetorozygosity in the NextSeq-150PE batch (i.e. sequencing errors are interpreted as true mutations). Therefore, using a more stringent base quality threshold for both batches can be an effective mitigation strategy. 

## Reference bias

Compared to longer paired-end reads, shorter single-end reads carrying bases that are different from the reference are less likely to be aligned to the reference genome (either correctly or incorrectly) with high confidence (e.g., due to the presence of an analogous sequence on the genome), and therefore tend to receive low mapping quality scores. As a result, when a strigent mapping quality threshold is imposed, shorter single-end reads are more likely to be affected. 

Here, we perform PCA and Fst estimation using samples from four Atlantic cod populations. Some of the samples were sequenced with paired-end 150bp reads, and others were sequenced with single-end 125bp reads. 

#### SNP calling and PCA

First, we perform SNP calling and PCA using ANGSD. 

```{bash eval=FALSE}
$ANGSD -b $BASEDIR/data/bam_list_rb.txt \
-anc $REFERENCE \
-out $BASEDIR/results/bam_list_rb \
-GL 1 -doGlf 2 -doMaf 1 -doMajorMinor 1 -doCounts 1 -doDepth 1 -dumpCounts 1 -doIBS 2 -makematrix 1 -doCov 1 -P 8 \
-SNP_pval 1e-6 -setMinDepth 10 -setMaxDepth 92 -minInd 2 -minQ 20 -minMaf 0.05 -minMapQ 20 

zcat $BASEDIR/results/bam_list_rb.mafs.gz | cut -f 1,2,3,4 | tail -n +2 > $BASEDIR/results/bam_list_rb.snp_list.txt
$ANGSD sites index $BASEDIR/results/bam_list_rb.snp_list.txt
```

```{r eval=FALSE, echo=FALSE}
test <- read_tsv("results/bam_list_rb.pos.gz")
test %>% 
  count(totDepth)
test %>% 
  count(totDepth) %>%
  ggplot(aes(y=n, x=totDepth)) +
  geom_line()
```

#### Get saf file per population

We get the sample allele frequency likelihoods (saf files) using ANGSD in each of the two batches. 

```{bash eval=FALSE}
## NextSeq-150PE
$ANGSD \
-b $BASEDIR/data/bam_list_rb_pe.txt \
-anc $REFERENCE \
-out $BASEDIR/results/bam_list_rb_pe \
-doSaf 1 \
-GL 1 \
-P 8 \
-doCounts 1 \
-dumpCounts 1 \
-setMinDepth 5 \
-minQ 20 \
-minmapq 20 \
-sites $BASEDIR/results/bam_list_rb.snp_list.txt

## HiSeq-125SE
$ANGSD \
-b $BASEDIR/data/bam_list_rb_se.txt \
-anc $REFERENCE \
-out $BASEDIR/results/bam_list_rb_se \
-doSaf 1 \
-GL 1 \
-P 8 \
-doCounts 1 \
-dumpCounts 1 \
-setMinDepth 5 \
-minQ 20 \
-minmapq 20 \
-sites $BASEDIR/results/bam_list_rb.snp_list.txt
```

#### Get 2dSFS and Fst

We compute Fst between the two batches. 

```{bash eval=FALSE}
$REALSFS \
$BASEDIR/results/bam_list_rb_pe.saf.idx \
$BASEDIR/results/bam_list_rb_se.saf.idx \
-P 8 \
-seed 42 \
-maxiter 500 \
> $BASEDIR/results/bam_list_rb_pe_bam_list_rb_se.2dSFS

$REALSFS fst index \
$BASEDIR/results/bam_list_rb_pe.saf.idx \
$BASEDIR/results/bam_list_rb_se.saf.idx \
-sfs $BASEDIR/results/bam_list_rb_pe_bam_list_rb_se.2dSFS \
-fstout $BASEDIR/results/bam_list_rb_pe_bam_list_rb_se.alpha_beta

$REALSFS fst print \
$BASEDIR/results/bam_list_rb_pe_bam_list_rb_se.alpha_beta.fst.idx \
> $BASEDIR/results/bam_list_rb_pe_bam_list_rb_se.alpha_beta.txt
```

#### Get depth in HiSeq-125SE batch without mapping quality filter

We count the sequencing depth at each SNP in the HiSeq-125SE batch without a mapping quality filter. 

```{bash eval=FALSE}
$ANGSD \
-b $BASEDIR/data/bam_list_rb_se.txt \
-anc $REFERENCE \
-out $BASEDIR/results/bam_list_rb_se_minmapq0 \
-P 8 \
-doCounts 1 \
-dumpCounts 1 \
-setMinDepth 2 \
-minQ 20 \
-minmapq 0 \
-sites $BASEDIR/results/bam_list_rb.snp_list.txt
```

#### Examine Fst results

Plot Fst in R.

```{r eval=TRUE, fig.height=2, fig.width=8}
basedir="/workdir/batch-effect/tutorial/"
fst <- read_tsv(str_c(basedir, "results/bam_list_rb_pe_bam_list_rb_se.alpha_beta.txt"), col_names = FALSE) %>%
  transmute(pos=X2, fst=X3/X4)
fst %>%
  ggplot(aes(x=pos, y=fst)) +
  geom_point(size=0.1) +
  theme_cowplot()
```

At some SNPs, Fst is very high between samples from the same populations but two different batches, which is not expected. Let's investigate what is causing such high Fst values.

#### Proportion of reads with lower mapping quality scores as a proxy for reference bias

We calculate the proportion of reads with mapping quality scores lower than 20 in the HiSeq-125SE batch for each SNP using R, and check whether this relates to the Fst outliers. 

```{r eval=TRUE, fig.width=8, fig.height=4}
## Depth in HiSeq-125SE without mapping quality filter
depth_minmapq0 <- read_tsv(str_c(basedir, "results/bam_list_rb_se_minmapq0.pos.gz")) %>%
  rename(minmapq0=totDepth)
## Depth in HiSeq-125SE with minimum mapping quality = 20
depth_minmapq20 <- read_tsv(str_c(basedir, "results/bam_list_rb_se.pos.gz"))%>%
  rename(minmapq20=totDepth)
## Calculate depth ratio for each SNP
depth_joined <- left_join(depth_minmapq20, depth_minmapq0) %>%
  mutate(depth_ratio=1-minmapq20/minmapq0) %>%
  dplyr::select(pos, depth_ratio)
## Join fst with depth ratio
fst_depth_ratio <- fst %>%
  left_join(depth_joined) %>%
  mutate(fst_outlier=fst>0.2)
## Fst vs. depth ratio
fst_depth_ratio %>%
  ggplot(aes(x=depth_ratio, y=fst)) +
  geom_point(size=0.2) +
  theme_cowplot()
## Get test stats
fst_depth_ratio %>%
  ggbetweenstats(y=depth_ratio, x=fst_outlier, output="subtitle", bf.message = FALSE)
fst_depth_ratio_stats <- fst_depth_ratio %>%
  centrality_description(fst_outlier, depth_ratio)
## Distrution of depth ratio in Fst outliers (those with Fst > 0.2) vs. all other SNPs
fst_depth_ratio %>%
  ggplot(aes(x=depth_ratio)) +
  geom_density(mapping = aes(fill=fst_outlier), alpha=0.3) +
  geom_vline(data=fst_depth_ratio_stats, aes(xintercept = depth_ratio)) +
  geom_label(data=fst_depth_ratio_stats, aes(label=expression), y=4, parse=TRUE) +
  scale_fill_viridis_d() +
  labs(x="proportion of reads with mapping quality lower than 20",
       y="density",
       subtitle=expression(paste(italic("t")["Welch"], "(", "49.09", ") = ", "-7.51", ", ", 
    italic("p"), " = ", "1.07e-09", ", ", widehat(italic("g"))["Hedges"], 
    " = ", "-1.30", ", CI"["95%"], " [", "-1.72", ", ", "-0.87", 
    "], ", italic("n")["obs"], " = ", "15,681"))) +
  theme_ggstatsplot() +
  theme(panel.grid = element_blank(),
        axis.line = element_line())
```


It is clear that Fst outliers are enriched in regions where a high proportion of single-end 125bp reads get low mapping quality scores, a signal of heightened level reference bias in one batch of our data. Therefore, we can exclude such SNPs (e.g., those with > 10% reads having mapping quality scores lower than 20 in the single-end 125bp batch) from the analysis. 

#### Fst before and after correction

```{r eval=TRUE, fig.width=8, fig.height=4}
fst_depth_ratio %>%
  filter(depth_ratio < 0.1) %>%
  mutate(type="after") %>%
  bind_rows(mutate(fst_depth_ratio, type="before")) %>%
  mutate(type=fct_relevel(type, c("before", "after"))) %>%
  ggplot(aes(x=pos, y=fst)) +
  geom_point(size=0.1) +
  facet_wrap(~type, ncol=1) +
  theme_cowplot()
```

On this segment of the genome, our mitigation strategy is particularly successful: almost all of the outlier SNPs are removed. 

#### Examine PCA results

```{r eval=TRUE}
basedir="/workdir/batch-effect/tutorial/"
sample_table <- read_tsv(str_c(basedir, "data/sample_table_rb.tsv"))
bam_list <- read_tsv(str_c(basedir, "data/bam_list_rb.txt"), col_names = FALSE) %>%
  transmute(sample_id=str_sub(X1, 37, 47))
genome_cov <- read_tsv(str_c(basedir, "results/bam_list_rb.covMat"), col_names = F)[1:nrow(sample_table),1:nrow(sample_table)] %>% as.matrix
pca_table <- eigen(genome_cov)$vectors %>% 
  as_tibble() %>%
  #transmute(PC1=V1, PC2=V2) %>%
  bind_cols(bam_list, .) %>%
  left_join(sample_table, ., by=c("sample_id_corrected"="sample_id"))
pca_table %>%
  ggplot(aes(x=V1, y=V2, color=data_type)) +
  facet_wrap(~population) +
  geom_point() +
  theme_cowplot()
```

Because this subset of our dataset is very small, individual level PCA has limited power, and therefore there is not a signal of batch effects in our PCA results. However, we still provide the code to mitigate batch effects when they are observed in the PCA results.

#### Corrected PCA

First, let's come up with a new SNP list excluding SNPs that are affected by reference bias.

```{r eval=FALSE}
## Come up with a new SNP list
read_tsv(str_c(basedir, "results/bam_list_rb.snp_list.txt"), col_names = FALSE) %>%
  semi_join(filter(fst_depth_ratio, depth_ratio < 0.1), by=c("X2"="pos")) %>%
  write_tsv(str_c(basedir, "results/bam_list_rb.depth_ratio_filtered_snp_list.txt"), col_names = FALSE)
```

Now, let's run PCA at this new SNP list.

```{bash eval=FALSE}
$ANGSD sites index $BASEDIR/results/bam_list_rb.depth_ratio_filtered_snp_list.txt

$ANGSD -b $BASEDIR/data/bam_list_rb.txt \
-anc $REFERENCE \
-out $BASEDIR/results/bam_list_rb_depth_ratio_filtered \
-GL 1 -doMajorMinor 1 -doCounts 1 -doIBS 2 -makematrix 1 -doCov 1 -P 8 \
-minQ 20 -minMapQ 20 \
-sites $BASEDIR/results/bam_list_rb.depth_ratio_filtered_snp_list.txt
```

```{r eval=TRUE}
basedir="/workdir/batch-effect/tutorial/"
sample_table <- read_tsv(str_c(basedir, "data/sample_table_rb.tsv"))
bam_list <- read_tsv(str_c(basedir, "data/bam_list_rb.txt"), col_names = FALSE) %>%
  transmute(sample_id=str_sub(X1, 37, 47))
genome_cov_depth_ratio_filtered <- read_tsv(str_c(basedir, "results/bam_list_rb_depth_ratio_filtered.covMat"), col_names = F)[1:nrow(sample_table),1:nrow(sample_table)] %>% as.matrix
pca_table_depth_ratio_filtered <- eigen(genome_cov_depth_ratio_filtered)$vectors %>% 
  as_tibble() %>%
  #transmute(PC1=V1, PC2=V2) %>%
  bind_cols(bam_list, .) %>%
  left_join(sample_table, ., by=c("sample_id_corrected"="sample_id"))
pca_table_depth_ratio_filtered %>%
  ggplot(aes(x=V1, y=V2, color=data_type)) +
  facet_wrap(~population) +
  geom_point() +
  theme_cowplot()
```

## DNA degradation

A major consequence of DNA degradation is deamination of cytosines (i.e., transition of C bases into U bases), causing enrichment of C-to-T and G-to-A substitutions in more degraded batches of data. Similar to base quality score miscalibration, these errors will also inflate diversity estimates, as degradation patterns will be regarded as true variants, and can cause batch effects if two batches of data are differentially degraded.

Here, we have samples from the same population, some of which are heavily degraded (determined by gDNA gel results), and some are relatively well preserved. We sequenced these samples in two different batches. To detect whether DNA degradation may cause an inflation of heterozygosity in the more degraded batch of samples, we estimation heterozygosity with and without transitions. 

#### Heterozygosity estimation

We use ANGSD to estimation heterozygosity including and excluding transtions. 

```{bash eval=FALSE}
MINDP=2
MAXDP=10
MINMAPQ=30
MINQ=33

for NOTRANS in {0,1}; do
  for LINE in `cat $BASEDIR/data/bam_list_degradation.txt`; do
      NAME_TEMP=`echo "${LINE%.*}"`
      NAME=`echo "${NAME_TEMP##*/}"`
  	  echo $NAME
      OUTBASE=$NAME'_mindp'$MINDP'_maxdp'$MAXDP'_minq'$MINQ'_minmapq'$MINMAPQ'_notrans'$NOTRANS
      
      ## Get saf file
      $ANGSD \
      -i $LINE \
      -anc $REFERENCE \
      -out $BASEDIR/results/$OUTBASE \
      -doSaf 1 \
      -GL 1 \
      -P 8 \
      -doCounts 1 \
      -setMinDepth $MINDP \
      -setMaxDepth $MAXDP \
      -minQ $MINQ \
      -minmapq $MINMAPQ \
      -noTrans $NOTRANS

      ## Estimate sfs
      /workdir/programs/angsd0.931/angsd/misc/realSFS \
      $BASEDIR/results/$OUTBASE'.saf.idx' \
      -tole 0.0000001 \
      -P 8 \
      -seed 42 \
      > $BASEDIR/results/$OUTBASE'.ml'
  done
done
```

#### Visualization

Using R, we compare the change in heterozygosity after transitions are excluded. 

```{r eval=TRUE, fig.width=6, fig.height=5}
basedir="/workdir/batch-effect/tutorial/"
sample_table <- read_tsv(str_c(basedir, "data/sample_table_degradation.tsv"))
for (i in seq_len(nrow(sample_table))){
  data_type <- sample_table$data_type[i]
  if (data_type=="se"){
    prefix <- str_c(sample_table$sample_seq_id[i], "_bt2_gadMor3_sorted_dedup_realigned_subsetted_mindp2_maxdp10_minq33_minmapq30_notrans")
  } else {
    prefix <- str_c(sample_table$sample_seq_id[i], "_bt2_gadMor3_sorted_dedup_overlapclipped_realigned_subsetted_mindp2_maxdp10_minq33_minmapq30_notrans")
  }
  for (notrans in c(0, 1)) {
    ml <- read_delim(str_c(basedir, "results/", prefix, notrans, ".ml"), col_names = FALSE, delim = " ")
    het <- ml$X2/(ml$X1 + ml$X2 + ml$X3)
    line <- tibble(het=het, sample_id=sample_table$sample_id_corrected[i], data_type=sample_table$data_type[i], notrans=notrans)
    if (i==1 & notrans==0) {
      het_final <- line
    } else{
      het_final <- bind_rows(het_final, line)
    }
  }
}

het_final %>%
  pivot_wider(names_from = notrans, values_from = het) %>%
  mutate(delta=`1`-`0`) %>%
  mutate(data_type=ifelse(data_type=="pe", "NextSeq-150PE (well-preserved)", "HiSeq-125SE (degraded)")) %>%
  mutate(data_type=factor(data_type, levels = c("NextSeq-150PE (well-preserved)", "HiSeq-125SE (degraded)"))) %>%
  ggstatsplot::ggbetweenstats(x = data_type, 
                              y = delta,  
                              type = "p", 
                              p.adjust.method = "holm",
                              pairwise.comparisons = TRUE,
                              ggsignif.args = list(textsize = 3),
                              ggplot.component = list(coord_cartesian(ylim=c(-0.005, 0.0001)),
                                                      theme(panel.grid = element_blank(),
                                                            axis.line = element_line()))) +
  #geom_signif(comparisons = list(c("pe\nless degraded", "se\nmore degraded"), c("se\nless degraded", "se\nmore degraded")), y_position = c(-0.001, -0.0012)) +
  ylab("change in heterozygosity estimates \nafter excluding transitions") +
  xlab("sample type") +
  geom_hline(yintercept = 0, linetype=2, color="red")
```

Exclusion of transitions will always cause a decrease in estimated heterozygosity. However, in this case, we see that the more degraded samples are more negatively affected by this exclusion, suggesting that the deamination of cytocines has caused a inflation of heterozygosity estimation if the transitions are included in the more degraded samples. Therefore, to compare batches of data with different DNA degradation levels, it is better to exclude the transitions (while bearing in mind that the absolute values of heterozygosity would be downward biased).


